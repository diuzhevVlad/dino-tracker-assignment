\documentclass[a4paper, 14pt]{extarticle}

% Текст
\usepackage[utf8]{inputenc} % UTF-8 кодировка
\usepackage[russian]{babel} % Русский язык
\usepackage{indentfirst} % красная строка в первом параграфе в главе
% Отображение страниц
\usepackage{geometry} % размеры листа и отступов
\geometry{
	left=30mm,
	top=20mm,
	right=15mm,
	bottom=25mm,
	marginparsep=0mm,
	marginparwidth=0mm,
	headheight=10mm,
	headsep=7mm,
	foot=0mm}
\usepackage{afterpage,fancyhdr} % настройка колонтитулов

\setlength{\baselineskip}{1.5em}
\usepackage{titlesec}
\renewcommand{\thesection}{}
\renewcommand{\thesubsection}{\arabic{subsection}}
\titleformat{\section}[block]{\centering\bfseries\Large}{}{5pt}{}
\titleformat{\subsection}[block]{\bfseries\large}{}{5pt}{}

\pagestyle{fancy}
\fancypagestyle{style}{ % создание нового стиля style
	\fancyhf{} % очистка колонтитулов
    \fancyhead[LO, RE]{\nouppercase{DINO-Tracker}} % название документа наверху
    \fancyhead[RO, LE]{\nouppercase{\leftmark}} % название section наверху
	\fancyfoot[C]{\thepage} % номер страницы справа внизу на нечетных и слева внизу на четных
	\renewcommand{\headrulewidth}{0.25pt} % толщина линии сверху
	\renewcommand{\footrulewidth}{0pt} % толцина линии снизу
}
\fancypagestyle{plain}{ % создание нового стиля plain -- полностью пустого
	\fancyhf{}
	\renewcommand{\headrulewidth}{0pt}
}
\fancypagestyle{title}{ % создание нового стиля title -- для титульной страницы
	\fancyhf{}
	\fancyhead[C]{{\footnotesize
			
	}}
	\fancyfoot[C]{{\large 
			Санкт-Петербург, 2024
	}}
	\renewcommand{\headrulewidth}{0pt}
}

% Математика
\usepackage{amsmath, amsfonts, amssymb, amsthm} % Набор пакетов для математических текстов
\usepackage{cancel} % зачеркивание для сокращений
% Рисунки и фигуры
\usepackage{graphicx} % вставка рисунков
\usepackage{epstopdf}
\usepackage{wrapfig, subcaption} % вставка фигур, обтекая текст
\usepackage{caption} % для настройки подписей
\captionsetup{figurewithin=none,labelsep=period, font={small,it}} % настройка подписей к рисункам
% Рисование
\usepackage{tikz} % рисование
\usepackage{circuitikz}
\usepackage{pgfplots} % графики
\usepgfplotslibrary{fillbetween}
% Таблицы
\usepackage{multirow} % объединение строк
\usepackage{multicol} % объединение столбцов
% Остальное
\usepackage[unicode, pdftex]{hyperref} % гиперссылки
\usepackage{enumitem} % нормальное оформление списков
\usepackage{float}

\setlist{itemsep=0.15cm,topsep=0.15cm,parsep=1pt} % настройки списков
% Теоремы, леммы, определения...
\theoremstyle{definition}
\newtheorem{Def}{Определение}
\newtheorem*{Axiom}{Аксиома}
\theoremstyle{plain}
\newtheorem{Th}{Теорема}
\newtheorem{Task}{Задание}
\newtheorem{Lem}{Лемма}
\newtheorem{Cor}{Следствие}
\newtheorem{Ex}{Пример}
\theoremstyle{remark}
\newtheorem*{Note}{Замечание}
\newtheorem*{Solution}{Решение}
\newtheorem*{Proof}{Доказательство}
% Свои команды
\newcommand{\comb}[1]{\left[\hspace{-4pt}\begin{array}{l}#1\end{array}\right.\hspace{-5pt} } % совокупность уравнений
\newcommand{\rank}{\mathrm{rank}\;}
% Титульный лист

\usepackage{listings}
\newcommand*{\titlePage}{
	\thispagestyle{title}
	\begingroup
	\begin{center}
		%		{\footnotesize
			%			Министерство образования и науки Российской Федерации\\
			%			Федеральное государственное автономное образовательное учреждение высшего образования
			%		}
		%		
		\vspace*{3ex}
		{\small
		}
		
		\vspace*{2ex}
		
		{\normalsize
		}
		
		\vspace*{30ex}
		
		{\Large \bfseries 
			Отчёт о выполнении тестового задания\\
			{\large <<DINO-Tracker: Taming DINO for Self-Supervised
			Point Tracking in a Single Video>>\\
				}
			
		}
		
	\end{center}
	\vspace*{10ex}
	\begin{flushright}
		{\large 
			\underline{Выполнил}: \textbf{Дюжев В. Д.}
		}

	\end{flushright}	
	\newpage
	\setcounter{page}{1}
	\endgroup}
%\usepackage{newtxmath,newtxtext}
%\lstset{literate={а}{\cyra}1{б}{\cyrb}1{в}{\cyrv}1{г}{\cyrg}1{д}{\cyrd}1{е}{\cyre}1{ж}{\cyrzh}1{з}{\cyrz}1{и}{\cyri}1{к}{\cyrk}1{л}{\cyrl}1{м}{\cyrm}1{н}{\cyrn}1{о}{\cyro}1{п}{\cyrp}1{р}{\cyrr}1{с}{\cyrs}1{т}{\cyrt}1{у}{\cyru}1{ф}{\cyrf}1{х}{h}1{ц}{w}1{ч}{\cyrch}1{ш}{\cyrsh}1{щ}{\cyrshch}1{ь}{m}1{ъ}{m}1{ы}{y}1{э}{e}1{ю}{\cyryu}1{я}{\cyrya}}

\lstset{basicstyle=\small}
\newcommand{\tasknum}[3]{Task}%\textunderscore{#1}\textunderscore{#2}y\textunderscore{#2}\textunderscore{#3}}
\usepackage{pdfpages}

\newcommand{\mat}[1]{\begin{pmatrix}#1\end{pmatrix}} 
\newcommand{\bmat}[1]{\begin{bmatrix}#1\end{bmatrix}} 

\newcommand{\code}[2]
{
\begin{minipage}{0.45\textwidth}
    \textbf{Code:}
    #1
\end{minipage}
}

\begin{document}
\renewcommand{\contentsname}{\hfillОГЛАВЛЕНИЕ\hfill} 
\titlePage
\thispagestyle{plain}
\tableofcontents
\pagestyle{style}

\newpage
\setcounter{page}{1}


\section{Введение}
\subsection{Краткое описание}
Dino-Tracker --- метод трекинга, созданный на основе модели DINOv2-ViT, которая используется как базовая для получения качественных обобщений изображений, содержащих важную семантическую информацию. Он позволяет добиться высокой точности, при этом относится к области self-supervised learning, что расширяет возможности его использования (т.к. нет необходимости разметки данных). Перед применением предполагается обучение на конкретном видео.

\subsection{Постановка задачи}
Дана последовательность кадров $\{I^t\}^T_{t=1}$, где $T$ --- длина видео. Задача состоит в обучении модели-трекера $\Pi$, принимающего на вход целевую точку $x_q$ (query point) и предсказывающего набор $\{\hat{x}^t\}^T_{t=1}$ --- траекторию данной точки (положения на всех кадрах). Целевая точка при этом задается положением и кадром (далее --- начальный кадр).
Таким образом итоговым результатом является возможность предсказания траектории любой точки любого кадра на протяжении всего видео.

\subsection{Структура отчета}
Данный отчет состоит из 5 секций:
\begin{enumerate}
	\item \textbf{Принцип работы} --- описание арихитектуры нейросетевой модели и алгоритмов постобработки, а также процесса обучения.
	\item \textbf{Запуск предобученной модели} --- содержит базовые результаты экспериментов с демонстрацией основных возможностей метода на предложенных в оригинальном репозитории данных.
	\item \textbf{Запуск на собственных данных} --- результаты обучения модели на собранных вручную реальных данных.
	\item \textbf{Техническая информация} --- описание процесса взаимодействия с ПО, дополнения к оригинальному репозиторию.
	\item \textbf{Выводы} --- подведение итогов, выдвижение гипотез для улучшения метода.
\end{enumerate}

\newpage

\section{Принцип работы}
\subsection{Идея}
Как говорилось ранее, в основе метода лежит предобученная модель DINOv2-ViT (визуальный трансформер) для формирования признаков, содержащих семантическую информацию (далее будем называть эту модель экстрактором признаков). 
В статье утверждается, что такие признаки, однако, имеют недостаточное содержание временной информации (для связей внутри видео). В качестве решения данной проблемы предлагается обучать дополнительную модель DELTA-DINO, формирующую добавки к выходу экстрактора признаков для формирования их уточнений. Уточненные признаки могут рассматриваться как обобщения для целой траектории, что в дальнейшем позволит сопоставлять точки на разных кадрах.

\subsection{Архитектура}
В простейшем случае входом сети является целевая точка $x_q$, ее начальный кадр $I^k$ и кадр $I^t$ для которого необходимо произвести предсказание положения $\hat{x}^t$. Обозначим выход модели DINOv2 как $\Phi_{DINO}(I)$, а выход DELTA-DINO как $\Phi_{\Delta}(I)$. Тогда в качестве уточненных признаков будем иметь:
\begin{equation}
	\Phi(I) = \Phi_{DINO}(I) + \Phi_{\Delta}(I).
\end{equation}

После получения представления для обоих кадров ($\Phi(I^k)$ и $\Phi(I^t)$) производится процесс сопоставления. Целевой точке $x_q$ на кадре $I^k$ ставится в соответствие признак $\varphi_q$ из $\Phi(I^k)$ путем билинейной интерполяции (т.к. размеры карты признаков уменьшены --- результат токенизации в DINOv2-ViT).

Далее происходит построение карты корреляции $S$ между признаками $\Phi(I^t)$ и $\varphi_q$ путем расчета косинусного расстояния:
\begin{equation}
	S(p) = \frac{\varphi_q^T \Phi^t(p)}{\|\varphi_q\|\|\Phi^t(p)\|},
\end{equation}
где $p$ --- обозначение положения на карте.

Для получения итоговой карты распределения вероятности $H$ нахождения целевой точки карта корреляции подается на вход сверточной сети (CNN-Refiner) с функцией Softmax на выходе.

Предсказание положения формируется как взвешенная сумма координат точек на карте распределения в окрестности точки (радиуса $R$) с наибольшей вероятностью ($x_{p_{\text{max}}}$):
\begin{equation}
	\hat{{x}}^t = \frac{\sum_{{p} \in \Omega} {H}({p}) \cdot {x}_{{p}}}{\sum_{{p} \in \Omega} {H}({p})},
\end{equation}
где \(\Omega = \{{p} : \|{x}_{{p}} - {x}_{{p}_{\text{max}}}\|_2 \leq R\}\). Итоговым предсказанием является \(\Pi({x}_q, t) = \hat{{x}}^t\), и траектория для \({x}_q\) --- \(\mathcal{T}_q = \{\hat{{x}}^t : \hat{{x}}^t = \Pi({x}_q, t), t = 1 \dots T\}\).

Ниже приведены подробности реализации описанного алгоритма.
\subsubsection{DINOv2-ViT}
DINOv2-ViT --- предобученный визуальный трансформер (используется модель ViT/14), широко применяемый как базовая модель экстракции признаков в области компьютерного зрения.
Являясь частью DINO-Tracker, его веса не участвуют в обучении. Единственным изменением, отличающим используемый экстрактор от оригинального является уменьшенный размер шага токенизации (7 вместо 14) для повышения разрешения карты признаков.
Для изображений 480x854 карта признаков имеет размерность 1024x67x121 (1024 --- размерность пространства признаков).
\subsubsection{DELTA-DINO}
Рассмотрим подробнее устройство модели DELTA-DINO. 
Эта сверточная сеть состоит только из 4 слоев со следующим преобразованием каналов: $[3 \to 64 \to 128 \to 256 \to 1024]$. 
Каждый слой, кроме последнего представляет собой комбинацию Conv2d (kernel:5, stride: 1, reflection padding: 2), BatchNorm2d, ReLU, BlurPool. 
Последний слой: Conv2d (kernel: 5, stride: 1, reflection padding: 4, dilation: 2), BatchNorm2d. 
На рисунке \ref{fig:delta-dino} представлена визуализация данной модели (размерности расчитаны с учетом входного изображения 480x854).

Важно отметить, что размерность выхода DELTA-DINO (1024x60x107) не совпадает с исходной размерность карты признаков DINOv2-ViT. Для расчета уточненных признаков необходимо совершить приведение к размерности признаков исходных. Данная задача решается методом линейной интерполяции координатной сеткой.

\subsubsection{CNN-Refiner}
Сверточная нейронная сеть на выходе имеет структуру: Conv2d (kernel: 3, padding: 1), ReLU, Conv2d (kernel: 3, padding: 1). Преобразование каналов: $[1 \to 16 \to 1]$. Таким образом, размерность карты распределения остается такой же как у карты корреляции.

\begin{figure}
    [H]
    \centering
    \includegraphics[height=0.95\textheight]{figs/Delta-DINO.gv.png}
    \caption{Архитектура DELTA-DINO (визуализация --- torchview).}
    \label{fig:delta-dino}
\end{figure}

\subsubsection{Денормализация}
Как было сказано в прошлом пункте, выходная карта распределения имеет размерность, совпадающую с картой корреляции и картой признаков.
Для работы алгоритма в исходной постановке необходимо вернуть предсказанные положения в размерность входных изображений. Для этого производится линейная денормализация предсказанного положения. Именно для обеспечения большей точности и <<гладкости>> данной процедуры сопоставления при расчете $\hat{x}^t$ применяетя взвешенная сумма.

\subsection{Обучение}
Обучение DINO-Tracker происходит в парадигме self-supervised learning на конкретном видео. 
Это подразумевает нахождение и использование закономерностей в данных для выполнения задачи. 
Предобработка данных представляет из себя расчет оптического потока (ОП) в видео, а также нахождение семантически близких точек в последовательности кадров (на основе признаков DINOv2-ViT).

\subsubsection{Обучающие наборы}
Набор соответсвующих друг другу точек, найденный на основе расчета оптического потока $\Omega_{\text{flow}}$ состоит из близких по кадрам точек (т.к. надежность оптического потока теряется со временем).

Для сэмплинга набора семантически близких точек $\Omega_{\text{DINO-bb}}$ используется принцип ближайших соседей:
\begin{equation}
	NN(\varphi_{\text{DINO}}^i, \Phi_{\text{DINO}}({I}^j)) = \varphi_{\text{DINO}}^j \land NN(\varphi_{\text{DINO}}^j, \Phi_{\text{DINO}}({I}^i)) = \varphi_{\text{DINO}}^i,
\end{equation}
где $NN(\varphi, \Phi)$ --- обозначение ближайшего соседа $\varphi$ в карте $\Phi$, $I^i, I^j$ --- выбранные кадры.
В процессе обучения аналогичным образом формируется набор $\Omega_{\text{rfn-bb}}$ на основе уточненных признаков.

\subsubsection{Функции потерь}
Задача оптимизации ставится для агрегированной функции потерь, состоящей из нескольких компонентов:
\begin{equation}
	\mathcal{L} = \mathcal{L}_{\text{flow}} + \lambda_1 \mathcal{L}_{\text{dino-bb}} + \lambda_2 \mathcal{L}_{\text{rfn-bb}} + \lambda_3 \mathcal{L}_{\text{rfn-cc}} + \lambda_4 \mathcal{L}_{\text{prior}},
\end{equation}
где $\{\lambda_i\}$ --- весовые коэффициенты, $\mathcal{L}_{\text{flow}}$ --- функция потерь ОП, $\mathcal{L}_{\text{dino-bb}}$ и $\mathcal{L}_{\text{rfn-bb}}$ --- функции потерь семантически схожих точек (на основе сырых и уточненных признаков), $\mathcal{L}_{\text{rfn-cc}}$ --- функция потерь циклической согласованности, $\mathcal{L}_{\text{prior}}$ --- функция потерь априорной информации.

В некоторых последующих формулах применяется функция потерь Хубера:
\begin{equation}
	L_H(x, y) = \begin{cases}
		0.5\|x-y\|^2, \|x - y\| < 1 \\
		\|x-y\| - 0.5, \|x-y\| \ge 1
	\end{cases}
\end{equation}

\textbf{Потери ОП}

Функция представляет собой вычисление суммы ошибок для прямого и обратоного потока:
\begin{equation}
	\mathcal{L}_{\text{flow}} = \sum_{(x^i, x^j) \in \Omega_{\text{flow}}} L_H(\Pi(x^i, j), x^j) + L_H(\Pi(x^j, i), x^i)
\end{equation}

\textbf{Потери семантически схожих точек}

Ставится цель увеличения корреляции между уточненными признаками семантически схожих точек и уменьшения корреляции с остальными. Для этого расчитывается <<contrustive loss>> (широко применяется в задачах self-supervised learning) между парами из $\Omega_{\text{dino-bb}}$:
\begin{equation}
	l(\varphi^i, \varphi^j) = -\log \frac{\exp(\text{cos-sim}(\varphi^i, \varphi^j) / \tau)}{\sum_p \exp(\text{cos-sim}(\varphi^i, \Phi^j(p)) / \tau)},
\end{equation}
где $\tau$ --- параметр <<температуры>>, регулирующий гладкость.

Итоговая функция потерь имеет вид:
\begin{equation}
	\mathcal{L}_{\text{dino-bb}} = \frac{1}{|\Omega_{\text{dino-bb}}|} \sum_{(\varphi^i, \varphi^j) \in \Omega_{\text{dino-bb}}} \frac{1}{2} w_{\text{dino-bb}}^{ij} \left( l(\varphi^i, \varphi^j) + l(\varphi^j, \varphi^i) \right),
\end{equation}
где $\{w_{\text{dino-bb}}^{ij}\}$ --- веса, рассчитываемые на основе величины веренности в сходстве.

$\mathcal{L}_{\text{rfn-bb}}$ определяется аналогичным образом.

\textbf{Потери циклической согласованности}

Важным свойством трекера должна быть циклическая согласованность, а именно: если $x^j = \Pi(x^i,j)$, то $x^i\approx\Pi(x^j,i)$. Функция потерь формулируется с учетом этого:
\begin{equation}
	\mathcal{L}_{\text{rfn-cc}} = \sum_{(x^i, x^j) \in \Omega_{\text{rfn-cc}}} \frac{1}{2} w_{\text{rfn-cc}}^{ij} \left( L_H(\Pi(x^i, j), x^j) + L_H(\Pi(x^j, i), x^i) \right),
\end{equation}
где $\{w_{\text{rfn-cc}}^{ij}\}$ --- веса, расчитанные на основе ошибки циклической согласованности.

\textbf{Потери априорной информации}

Признаки полученные напрямую от DINOv2-ViT обладают высокой обобщающей способностью и содержат важную семантическую априорную информацию. Для ее сохранения вводится функция потерь, поощряющая сохранение нормы и ориентации уточненных признаков (для каждого кадра).
\begin{equation}
	\mathcal{L}_{\text{prior}} = \frac{1}{H' \cdot W'} \cdot \sum_p \left| 1 - \frac{\|\Phi(I)[p]\|_2}{\|\Phi_{\text{DINO}}(I)[p]\|_2}\right| + \left| 1 - \text{cos-sim}(\Phi(I)[p], \Phi_{\text{DINO}}(I)[p])\right|,
\end{equation}
где $H', W'$ --- размеры карты признаков.

\subsubsection{Гиперпараметры (In progress)}

\newpage

\section{Запуск предобученной модели}
В данной секции представлены результаты использования модели DINO-Tracker на последовательностях из датасета 
Tapvid-Davis-480. Данные доступны по \href{https://www.dropbox.com/scl/fo/7s2rgsm92qbzzh2xnx51d/AIvXxRaJPL2RQm43Zi_taJU?e=1&preview=davis_480.zip&rlkey=6cs0bm2u0on1u7z0jyxlq8avq&st=7s75r77a&dl=0}{ссылке}, указанной в репозитории.
\subsection{Базовая визуализация}
В качестве примеров для демострации работоспособности базовой модели DINO-Tracker (предсказаний нейросетевой части, без постобработки) были выбраны видео-последовательности с достаточно простым профилем движения, без явных окклюзий. На рисунках \ref{fig:davis-29}-\ref{fig:davis-21} изображены по 3 кадра (первый, центральный и последний) с демонстрацией промежуточных траекторий для целевых точек (начальным кадром во всех случаях является первый).
\begin{figure}
    [H]
    \centering
    \includegraphics[width=\textwidth]{figs/davis-29.png}
    \caption{Траектории DINO-Tracker. Tapvid-Davis-480/29.}
    \label{fig:davis-29}
\end{figure}
\begin{figure}
    [H]
    \centering
    \includegraphics[width=\textwidth]{figs/davis-26.png}
    \caption{Траектории DINO-Tracker. Tapvid-Davis-480/26.}
    \label{fig:davis-26}
\end{figure}
\begin{figure}
    [H]
    \centering
    \includegraphics[width=\textwidth]{figs/davis-21.png}
    \caption{Траектории DINO-Tracker. Tapvid-Davis-480/21.}
    \label{fig:davis-21}
\end{figure}

Можем заметить, что полученные траектории имеют естественный вид. 
Базовый метод может быть успешно применен и к трекингу в более сложных окружениях 
(рисунок \ref{fig:davis-13}), однако важно чтобы целевая точка находилась в достаточно 
уникальной части изображения и не подвергалась окклюзиям. Например, на рисунке 
\ref{fig:davis-15} видно, что целевая точка сопоставляется неправильно с определенного 
момента времени (из-за появления схожего объекта и окклюзии первоначальной цели). 
Данные ограничения помогает во многом снять постобработка с предсказанием окклюзий, 
о которой будет сказано в дальнейшем.

\begin{figure}
    [H]
    \centering
    \includegraphics[width=\textwidth]{figs/davis-13.png}
    \caption{Траектории DINO-Tracker. Tapvid-Davis-480/13.}
    \label{fig:davis-13}
\end{figure}
\begin{figure}
    [H]
    \centering
    \includegraphics[width=\textwidth]{figs/davis-15.png}
    \caption{Траектории DINO-Tracker. Tapvid-Davis-480/15.}
    \label{fig:davis-15}
\end{figure}

\subsection{Метрики качества}

Оценка качества трекинга производится на датасете Tapvid-Davis-480 согласно инструкции, указанной в репозитории (также есть возможность провести оценку на других предложенных наборах данных, однако ввиду длительности процесса был выбран один из них).

Для оценки исполбзуются метрики, предложенные в оригинальной статье <<TAP-Vid: A Benchmark for Tracking Any Point in a Video>>: 
\begin{enumerate}
    \item occlusion accuracy ($OA$) --- отношение количества правильно предсказанных окклюзий в последовательности к длине последовательности (стандартная accuracy классификации);
    \item position accuracy ($<\delta^x$) --- отношение количества правильно предсказанных положений видимых точек (без окклюзий) последовательности к количеству видимых точек, где правильными считаются предсказания, лежащие в заданной окрестности (в пикселях) действительных значений;
    \item jaccard --- объединенная метрика для оценки качества предсказаний окклюзий и положений, рассчитываемая как отношение количества правильно предсказанных положений видимых точек с соответствующим правильным предсказанием окклюзий последовательности к количеству видимых точек + количеству неправильно классифицированных невидимых точек или точек с неправильными предсказаниями положений, предсказанных видимыми.
\end{enumerate}
Важно отметить, что метрики $<\delta^x$ и jaccard рассчитываются для всех изображений последовательности (кроме начальных для соответствующих ключевых точек) с учетом приведения к размеру 256x256.
В качестве итоговых метрик выступают $OA$, average jaccard ($AJ$) и average position accuracy ($<\delta^x_{avg}$), где поледние две расчитываются как средние значения jaccard и $<\delta^x$ для окрестностей в 1, 2, 4, 8 и 16 пикселей.
\begin{table}[!ht]
    \centering
    \begin{tabular}{|l|l|l|l || l|l|l|l|}
    \hline
	\textbf{id} & \textbf{$OA$} & \textbf{$AJ$} & \textbf{$<\delta^x_{avg}$} & \textbf{id} & \textbf{$OA$} & \textbf{$AJ$} & \textbf{$<\delta^x_{avg}$} \\ \hline
        25 & 0.86407 & 0.52461 & 0.71564 & 23 & 0.88914 & 0.70477 & 0.8492 \\ \hline
        7 & 0.84293 & 0.62454 & 0.82839 & 14 & 0.95139 & 0.64647 & 0.75761 \\ \hline
        20 & 0.83599 & 0.5811 & 0.77156 & 13 & 0.89146 & 0.59985 & 0.72462 \\ \hline
        1 & 0.83536 & 0.55336 & 0.77867 & 29 & 0.96237 & 0.78638 & 0.87435 \\ \hline
        26 & 0.92519 & 0.72271 & 0.84825 & 17 & 0.89871 & 0.61162 & 0.75912 \\ \hline
        5 & 0.87887 & 0.60303 & 0.8446 & 4 & 0.87391 & 0.66864 & 0.88173 \\ \hline
        2 & 0.69653 & 0.37687 & 0.72344 & 11 & 0.79149 & 0.57035 & 0.7935 \\ \hline
        19 & 0.82501 & 0.47515 & 0.70126 & 16 & 1.0 & 0.94087 & 0.96645 \\ \hline
        6 & 0.85056 & 0.63005 & 0.80656 & 10 & 0.94926 & 0.76182 & 0.86853 \\ \hline
        22 & 0.79057 & 0.54181 & 0.76219 & 3 & 0.91635 & 0.75579 & 0.8585 \\ \hline
        8 & 0.88787 & 0.69386 & 0.84002 & 21 & 0.98371 & 0.84777 & 0.90917 \\ \hline
        28 & 0.93551 & 0.73576 & 0.84587 & 24 & 0.94805 & 0.8512 & 0.9379 \\ \hline
        0 & 0.99963 & 0.64083 & 0.72042 & 15 & 0.96577 & 0.80356 & 0.87399 \\ \hline
        9 & 0.69041 & 0.29614 & 0.5251 & 18 & 0.81178 & 0.52368 & 0.71774 \\ \hline
        27 & 0.87957 & 0.62347 & 0.7801 & 12 & 0.99365 & 0.88775 & 0.93579  \\ \hline
        \hline
        \textit{\textbf{avg}} & \textit{\textbf{0.8855} }& \textit{\textbf{0.65279}} & \textit{\textbf{0.80668}} & --- & --- & --- & --- \\ \hline
    \end{tabular}
	\caption{Метрики качества. Датасет Tapvid-Davis-480.}
\end{table}

В статье завлены следующие данные для рассматриваемого датасета:
$OA=0.881, AJ=0.646, <\delta^x_{avg}=0.804$. Эксперимент подтверждает достижение таких значений.
	
\subsection{Производительность}
Эксперименты производятся на устройстве Lenovo Legion 7 (AMD Ryzen 9 5900HX, NVIDIA GeForce RTX 3080 120W 16Gb, 32 Gb RAM).

Для получения данных о производительности в инференсе метод был применен ко всем последовательностям из датасета. Эксперимент проводился только для нейросетевой части DINO-Tracker. Дальнейшее предсказание окклюзий сильно зависит от контекста изображения.
На вход модели подавалась одна ключевая точка, соответсвующая центру первого кадра. Принятый размер батча: $1$.
Ниже приведен график, иллюстрирующий зависимость времени обработки видео от количества кадров в нем. 
\begin{figure}
    [H]
    \centering
    \includegraphics[width=\textwidth]{figs/performance.png}
    \caption{Зависимость времени инференса нейросетевой части DINO-Tracker от количества кадров.}
    \label{fig:performance}
\end{figure}

Алгоритм обработки видео последовательно предсказывает положение целевой точки на кадрах. Данные подтверждают, что зависимость является линейной. Аппроксимировав ее моделью линейной регрессиии без смещения получим, что на предсказание позиции целевой точки в одном кадре тратится в среднем $0.0041$ [с].

В процессе инференса в среднем затрачивалось 14.5 Гб видеопамяти.

\subsection{Мульти-трекинг}
Задача множественного трекинга объектов подразумевает наличие механизма сопоставление объектов траекториями движения (ассоциация данных). Базовый метод DINO-Tracker не использует данную процедуру. Как видно на примерах, представленных выше (рисунки \ref{fig:davis-13}, \ref{fig:davis-15}) в такой конфигурации он может быть применен при отсутствии явных окклюзий и достаточном количестве семантически уникальных точек на объектах.

При использовании постобработки (предсказания окклюзий) область применения метода для задач множественного трекинга можно существенно расширить. По сути, в алгоритме обработки окклюзий частично применяется подход ассоциации --- проверяеется схожесть траекторий на разных участках видео согласно установленному критерию. На рисунке \ref{fig:davis-8} показаны положения целевых точек (1 и 30 кадр), изначально расположенных на объектах.
\begin{figure}
    [H]
    \centering
    \includegraphics[width=\textwidth]{figs/davis-8.png}
    \caption{Трекинг точек на нескольких объектах. Tapvid-Davis-480/8.}
    \label{fig:davis-8}
\end{figure}

Можно предположить, что произведя изначальную детекцию объектов и выбрав наборы целевых точек, соответствующие им производить трекинг объектов как среднее положение всех видимых соответствующих ему точек.
Однако такой подход требует усовершенствавания для обработки новых объектов появляющихся на видео (что в итоге возвращает к задаче верхнеуровневой ассоциации данных). Кроме того, даже с учетом обработки окклюзий семантически близкие точки могут неверно сопоставляться.
\newpage

\section{Запуск на собственных данных (In progress)}
\newpage


\section{Техническая информации (In progress)}
\newpage


\section{Выводы (In progress)}
\newpage


\end{document}
\input{metrics_table}

