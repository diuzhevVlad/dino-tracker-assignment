\documentclass[a4paper, 14pt]{extarticle}

% Текст
\usepackage[utf8]{inputenc} % UTF-8 кодировка
\usepackage[russian]{babel} % Русский язык
\usepackage{indentfirst} % красная строка в первом параграфе в главе
% Отображение страниц
\usepackage{geometry} % размеры листа и отступов
\geometry{
	left=30mm,
	top=20mm,
	right=15mm,
	bottom=25mm,
	marginparsep=0mm,
	marginparwidth=0mm,
	headheight=10mm,
	headsep=7mm,
	foot=0mm}
\usepackage{afterpage,fancyhdr} % настройка колонтитулов

\setlength{\baselineskip}{1.5em}
\usepackage{titlesec}
\renewcommand{\thesection}{}
\renewcommand{\thesubsection}{\arabic{subsection}}
\titleformat{\section}[block]{\centering\bfseries\Large}{}{5pt}{}
\titleformat{\subsection}[block]{\bfseries\large}{}{5pt}{}

\pagestyle{fancy}
\fancypagestyle{style}{ % создание нового стиля style
	\fancyhf{} % очистка колонтитулов
    \fancyhead[LO, RE]{\nouppercase{DINO-Tracker}} % название документа наверху
    \fancyhead[RO, LE]{\nouppercase{\leftmark}} % название section наверху
	\fancyfoot[C]{\thepage} % номер страницы справа внизу на нечетных и слева внизу на четных
	\renewcommand{\headrulewidth}{0.25pt} % толщина линии сверху
	\renewcommand{\footrulewidth}{0pt} % толцина линии снизу
}
\fancypagestyle{plain}{ % создание нового стиля plain -- полностью пустого
	\fancyhf{}
	\renewcommand{\headrulewidth}{0pt}
}
\fancypagestyle{title}{ % создание нового стиля title -- для титульной страницы
	\fancyhf{}
	\fancyhead[C]{{\footnotesize
			
	}}
	\fancyfoot[C]{{\large 
			Санкт-Петербург, 2024
	}}
	\renewcommand{\headrulewidth}{0pt}
}

% Математика
\usepackage{amsmath, amsfonts, amssymb, amsthm} % Набор пакетов для математических текстов
\usepackage{cancel} % зачеркивание для сокращений
% Рисунки и фигуры
\usepackage{graphicx} % вставка рисунков
\usepackage{epstopdf}
\usepackage{wrapfig, subcaption} % вставка фигур, обтекая текст
\usepackage{caption} % для настройки подписей
\captionsetup{figurewithin=none,labelsep=period, font={small,it}} % настройка подписей к рисункам
% Рисование
\usepackage{tikz} % рисование
\usepackage{circuitikz}
\usepackage{pgfplots} % графики
\usepgfplotslibrary{fillbetween}
% Таблицы
\usepackage{multirow} % объединение строк
\usepackage{multicol} % объединение столбцов
% Остальное
\usepackage[unicode, pdftex]{hyperref} % гиперссылки
\usepackage{enumitem} % нормальное оформление списков
\usepackage{float}

\setlist{itemsep=0.15cm,topsep=0.15cm,parsep=1pt} % настройки списков
% Теоремы, леммы, определения...
\theoremstyle{definition}
\newtheorem{Def}{Определение}
\newtheorem*{Axiom}{Аксиома}
\theoremstyle{plain}
\newtheorem{Th}{Теорема}
\newtheorem{Task}{Задание}
\newtheorem{Lem}{Лемма}
\newtheorem{Cor}{Следствие}
\newtheorem{Ex}{Пример}
\theoremstyle{remark}
\newtheorem*{Note}{Замечание}
\newtheorem*{Solution}{Решение}
\newtheorem*{Proof}{Доказательство}
% Свои команды
\newcommand{\comb}[1]{\left[\hspace{-4pt}\begin{array}{l}#1\end{array}\right.\hspace{-5pt} } % совокупность уравнений
\newcommand{\rank}{\mathrm{rank}\;}
% Титульный лист

\usepackage{listings}

\lstdefinestyle{mystyle}{
    % backgroundcolor=\color{gray!10},    % slightly gray background
    commentstyle=\color{olive},        % comments in olive
    keywordstyle=\color{blue},         % keywords in blue
    stringstyle=\color{teal},          % strings in teal
    basicstyle=\ttfamily\footnotesize, % typewriter font, small size
    numberstyle=\tiny\color{gray},     % line numbers in gray, tiny size
    % numbers=left,                      % line numbers on the left
    frame=single,                      % single border around code
    rulecolor=\color{black},           % border color
    columns=fullflexible,              % better spacing
    breaklines=true,                   % line breaking
    breakatwhitespace=false,
    tabsize=4,
    showstringspaces=false
}
\newcommand*{\titlePage}{
	\thispagestyle{title}
	\begingroup
	\begin{center}
		%		{\footnotesize
			%			Министерство образования и науки Российской Федерации\\
			%			Федеральное государственное автономное образовательное учреждение высшего образования
			%		}
		%		
		\vspace*{3ex}
		{\small
		}
		
		\vspace*{2ex}
		
		{\normalsize
		}
		
		\vspace*{30ex}
		
		{\Large \bfseries 
			Отчёт о выполнении тестового задания\\
			{\large <<DINO-Tracker: Taming DINO for Self-Supervised
			Point Tracking in a Single Video>>\\
				}
			
		}
		
	\end{center}
	\vspace*{10ex}
	\begin{flushright}
		{\large 
			\underline{Выполнил}: \textbf{Дюжев В. Д.}
		}

	\end{flushright}	
	\newpage
	\setcounter{page}{1}
	\endgroup}
%\usepackage{newtxmath,newtxtext}
%\lstset{literate={а}{\cyra}1{б}{\cyrb}1{в}{\cyrv}1{г}{\cyrg}1{д}{\cyrd}1{е}{\cyre}1{ж}{\cyrzh}1{з}{\cyrz}1{и}{\cyri}1{к}{\cyrk}1{л}{\cyrl}1{м}{\cyrm}1{н}{\cyrn}1{о}{\cyro}1{п}{\cyrp}1{р}{\cyrr}1{с}{\cyrs}1{т}{\cyrt}1{у}{\cyru}1{ф}{\cyrf}1{х}{h}1{ц}{w}1{ч}{\cyrch}1{ш}{\cyrsh}1{щ}{\cyrshch}1{ь}{m}1{ъ}{m}1{ы}{y}1{э}{e}1{ю}{\cyryu}1{я}{\cyrya}}

\lstset{basicstyle=\small}
\newcommand{\tasknum}[3]{Task}%\textunderscore{#1}\textunderscore{#2}y\textunderscore{#2}\textunderscore{#3}}
\usepackage{pdfpages}

\newcommand{\mat}[1]{\begin{pmatrix}#1\end{pmatrix}} 
\newcommand{\bmat}[1]{\begin{bmatrix}#1\end{bmatrix}} 

\newcommand{\code}[2]
{
\begin{minipage}{0.45\textwidth}
    \textbf{Code:}
    #1
\end{minipage}
}

\begin{document}
\renewcommand{\contentsname}{\hfillОГЛАВЛЕНИЕ\hfill} 
\titlePage
\thispagestyle{plain}
\tableofcontents
\pagestyle{style}

\newpage
\setcounter{page}{1}


\section{Введение}
\subsection{Краткое описание}
Dino-Tracker --- метод трекинга, созданный на основе модели DINOv2-ViT, которая используется как базовая для получения качественных обобщений изображений, содержащих важную семантическую информацию. Он позволяет добиться высокой точности, при этом относится к области self-supervised learning, что расширяет возможности его использования (т.к. нет необходимости разметки данных). Перед применением предполагается обучение на конкретном видео.

\subsection{Постановка задачи}
Дана последовательность кадров $\{I^t\}^T_{t=1}$, где $T$ --- длина видео. Задача состоит в обучении модели-трекера $\Pi$, принимающего на вход целевую точку $x_q$ (query point) и предсказывающего набор $\{\hat{x}^t\}^T_{t=1}$ --- траекторию данной точки (положения на всех кадрах). Целевая точка при этом задается положением и кадром (далее --- начальный кадр).
Таким образом итоговым результатом является возможность предсказания траектории любой точки каждого кадра на протяжении всего видео.

\subsection{Структура отчета}
Данный отчет состоит из 5 секций:
\begin{enumerate}
	\item \textbf{Принцип работы} --- описание архитектуры нейросетевой модели и алгоритма классификации окклюзий, а также процесса обучения.
	\item \textbf{Запуск предобученной модели} --- содержит базовые результаты экспериментов с демонстрацией основных возможностей метода на предложенных в оригинальном репозитории данных.
	\item \textbf{Запуск на собственных данных} --- результаты обучения модели на собранных вручную реальных данных.
	\item \textbf{Техническая информация} --- описание процесса взаимодействия с ПО, дополнения к оригинальному репозиторию.
	\item \textbf{Выводы} --- подведение итогов, выдвижение гипотез для улучшения метода.
\end{enumerate}

Видео-материалы к выполненным экспериментам могут быть найдены по \href{https://drive.google.com/drive/folders/1OhjDO-olEEyySXN8FETYPrz6gLZjzuJF?usp=drive_link}{ссылке}.

\newpage

\section{Принцип работы}
\subsection{Идея}
Как говорилось ранее, в основе метода лежит предобученная модель DINOv2-ViT (визуальный трансформер) для формирования признаков, содержащих семантическую информацию (далее будем называть эту модель экстрактором признаков). 
В статье утверждается, что такие признаки, однако, имеют недостаточное содержание временной информации (для связей внутри видео). В качестве решения данной проблемы предлагается обучать дополнительную модель DELTA-DINO, формирующую добавки к выходу экстрактора признаков для формирования их уточнений. Уточненные (refined) признаки могут рассматриваться как обобщения для целой траектории, что в дальнейшем позволит сопоставлять точки на разных кадрах.

\subsection{Архитектура}
В простейшем случае входом сети является целевая точка $x_q$, ее начальный кадр $I^k$ и кадр $I^t$ для которого необходимо произвести предсказание положения $\hat{x}^t$. Обозначим выход модели DINOv2 как $\Phi_{DINO}(I)$, а выход DELTA-DINO как $\Phi_{\Delta}(I)$. Тогда в качестве уточненных признаков будем иметь:
\begin{equation}
	\Phi(I) = \Phi_{DINO}(I) + \Phi_{\Delta}(I).
\end{equation}

После получения представления (карт признаков) для обоих кадров ($\Phi(I^k)$ и $\Phi(I^t)$) производится процесс сопоставления. Целевой точке $x_q$ на кадре $I^k$ ставится в соответствие признак $\varphi_q$ из $\Phi(I^k)$ путем билинейной интерполяции (т.к. размеры карты признаков уменьшены --- результат токенизации в DINOv2-ViT).

Далее происходит построение карты корреляции $S$ между признаками $\Phi(I^t)$ и $\varphi_q$ путем расчета косинусного расстояния:
\begin{equation}
	S(p) = \text{cos-sim}(\varphi_q, \Phi^t(p))= \frac{\varphi_q^T \Phi^t(p)}{\|\varphi_q\|\|\Phi^t(p)\|},
\end{equation}
где $p$ --- обозначение положения на карте признаков.

Для получения итоговой карты распределения вероятности $H$ нахождения целевой точки карта корреляции подается на вход сверточной сети (CNN-Refiner) с функцией Softmax на выходе.

Предсказание положения формируется как взвешенная сумма координат точек на карте распределения в окрестности радиуса $R$ точки с наибольшей вероятностью ($x_{p_{\text{max}}}$):
\begin{equation} \label{eq:prediction}
	\hat{{x}}^t = \frac{\sum_{{p} \in \Omega} {H}({p}) \cdot {x}_{{p}}}{\sum_{{p} \in \Omega} {H}({p})},
\end{equation}
где \(\Omega = \{{p} : \|{x}_{{p}} - {x}_{{p}_{\text{max}}}\|_2 \leq R\}\). Итоговым предсказанием является \(\Pi({x}_q, t) = \hat{{x}}^t\), и траектория для \({x}_q\) --- \(\mathcal{T}_q = \{\hat{{x}}^t : \hat{{x}}^t = \Pi({x}_q, t), t = 1 \dots T\}\).
\begin{figure}
    [H]
    \centering
    \includegraphics[width=0.95\textwidth]{figs/demo.png}
    \caption{Схема Dino-Tracker из статьи.}
    \label{fig:tracker-scheme}
\end{figure}

На рисунке \ref{fig:tracker-scheme} изображена схема работы метода от авторов статьи. Ниже приведены подробности реализации описанного алгоритма.
\subsubsection{DINOv2-ViT}
DINOv2-ViT --- предобученный визуальный трансформер (используется модель ViT/14 с выходом на 16 слое), широко применяемый как базовая модель экстракции признаков в области компьютерного зрения.
Являясь частью DINO-Tracker, его веса не участвуют в обучении. Единственным изменением, отличающим используемый экстрактор от оригинального является уменьшенный размер шага токенизации (7 вместо 14) для повышения разрешения карты признаков.
Для изображений 480x854 карта признаков имеет размерность 1024x67x121 (1024 --- размерность пространства признаков).
\subsubsection{DELTA-DINO}
Рассмотрим подробнее устройство модели DELTA-DINO. 
Эта сверточная сеть состоит только из 4 слоев со следующим преобразованием каналов: $[3 \to 64 \to 128 \to 256 \to 1024]$. 
Каждый слой, кроме последнего представляет собой комбинацию Conv2d (kernel:5, stride: 1, reflection padding: 2), BatchNorm2d, ReLU, BlurPool. 
Последний слой: Conv2d (kernel: 5, stride: 1, reflection padding: 4, dilation: 2), BatchNorm2d. 
На рисунке \ref{fig:delta-dino} представлена визуализация данной модели (размерности рассчитаны с учетом входного изображения 480x854).

\begin{figure}
    [H]
    \centering
    \includegraphics[height=0.95\textheight]{figs/Delta-DINO.gv.png}
    \caption{Архитектура DELTA-DINO (визуализация --- torchview).}
    \label{fig:delta-dino}
\end{figure}

Важно отметить, что размерность выхода DELTA-DINO (1024x60x107) не совпадает с исходной размерность карты признаков DINOv2-ViT. Для расчета уточненных признаков необходимо совершить приведение к размерности признаков исходных. Данная задача решается методом линейной интерполяции координатной сеткой.

\subsubsection{CNN-Refiner}
Сверточная нейронная сеть на выходе имеет структуру: Conv2d (kernel: 3, padding: 1), ReLU, Conv2d (kernel: 3, padding: 1). Преобразование каналов: $[1 \to 16 \to 1]$. Таким образом, размерность карты распределения остается такой же, как у карты корреляции.



\subsubsection{Денормализация}
Как было сказано в прошлом пункте, выходная карта распределения имеет размерность, совпадающую с картой корреляции и картой признаков.
Для работы алгоритма в исходной постановке необходимо вернуть предсказанные положения в размерность входных изображений. Для этого производится линейная денормализация предсказанного положения. Именно для обеспечения большей точности и <<гладкости>> данной процедуры сопоставления при расчете $\hat{x}^t$ применяется взвешенная сумма.

\subsection{Обучение}
Обучение DINO-Tracker происходит в парадигме self-supervised learning на конкретном видео. 
Это подразумевает нахождение и использование закономерностей в данных для выполнения задачи (возможно промежуточной и не являющейся целевой). 
Предобработка данных представляет собой расчет оптического потока (ОП) в видео, а также нахождение семантически близких точек (best-buddies) в последовательности кадров на основе признаков DINOv2-ViT. Эти данные сформируют подобие обучающей выборки для трекинга точек.

\subsubsection{Обучающие наборы}
Набор соответствующих друг другу точек, найденный на основе расчета оптического потока $\Omega_{\text{flow}}$ состоит из близких по кадрам точек (т.к. надежность оптического потока теряется со временем).

Для сэмплинга набора семантически близких точек $\Omega_{\text{DINO-bb}}$ используется принцип ближайших соседей:
\begin{equation}
	NN(\varphi_{\text{DINO}}^i, \Phi_{\text{DINO}}({I}^j)) = \varphi_{\text{DINO}}^j \land NN(\varphi_{\text{DINO}}^j, \Phi_{\text{DINO}}({I}^i)) = \varphi_{\text{DINO}}^i,
\end{equation}
где $NN(\varphi, \Phi)$ --- обозначение ближайшего соседа $\varphi$ в карте признаков $\Phi$, а $I^i, I^j$ --- выбранные кадры.
В процессе обучения аналогичным образом формируется набор $\Omega_{\text{rfn-bb}}$ на основе уточненных признаков.

\subsubsection{Функции потерь}
Задача оптимизации ставится для агрегированной функции потерь, состоящей из нескольких компонентов:
\begin{equation} \label{eq:loss}
	\mathcal{L} = \mathcal{L}_{\text{flow}} + \lambda_1 \mathcal{L}_{\text{dino-bb}} + \lambda_2 \mathcal{L}_{\text{rfn-bb}} + \lambda_3 \mathcal{L}_{\text{rfn-cc}} + \lambda_4 \mathcal{L}_{\text{prior}},
\end{equation}
где $\{\lambda_i\}$ --- весовые коэффициенты, $\mathcal{L}_{\text{flow}}$ --- функция потерь ОП, $\mathcal{L}_{\text{dino-bb}}$ и $\mathcal{L}_{\text{rfn-bb}}$ --- функции потерь семантически схожих точек (на основе сырых и уточненных признаков), $\mathcal{L}_{\text{rfn-cc}}$ --- функция потерь циклической согласованности, $\mathcal{L}_{\text{prior}}$ --- функция потерь априорной информации.

В некоторых последующих формулах применяется функция потерь Хубера:
\begin{equation}
	L_H(x, y) = \begin{cases}
		0.5\|x-y\|^2, \|x - y\| < \delta \\
		\delta(\|x-y\| - 0.5\delta), \|x-y\| \ge \delta
	\end{cases}
\end{equation}
В реализации, предложенной авторами $\delta=\frac{1}{32}$.

\textbf{Потери ОП}

Функция представляет собой вычисление суммы ошибок для прямого и обратного потока:
\begin{equation}
	\mathcal{L}_{\text{flow}} = \sum_{(x^i, x^j) \in \Omega_{\text{flow}}} L_H(\Pi(x^i, j), x^j) + L_H(\Pi(x^j, i), x^i)
\end{equation}

\textbf{Потери семантически схожих точек}

Ставится цель увеличения корреляции между уточненными признаками семантически схожих точек и уменьшения корреляции с остальными. Для этого рассчитывается <<contrustive loss>> (широко применяется в задачах self-supervised learning) между парами из $\Omega_{\text{dino-bb}}$:
\begin{equation} \label{eq:bb-loss}
	l(\varphi^i, \varphi^j) = -\log \frac{\exp(\text{cos-sim}(\varphi^i, \varphi^j) / \tau)}{\sum_p \exp(\text{cos-sim}(\varphi^i, \Phi^j(p)) / \tau)},
\end{equation}
где $\tau$ --- параметр <<температуры>>, регулирующий гладкость.

Итоговая функция потерь имеет вид:
\begin{equation}
	\mathcal{L}_{\text{dino-bb}} = \frac{1}{|\Omega_{\text{dino-bb}}|} \sum_{(\varphi^i, \varphi^j) \in \Omega_{\text{dino-bb}}} \frac{1}{2} w_{\text{dino-bb}}^{ij} \left( l(\varphi^i, \varphi^j) + l(\varphi^j, \varphi^i) \right),
\end{equation}
где $\{w_{\text{dino-bb}}^{ij}\}$ --- веса, рассчитываемые на основе величины уверенности в сходстве.

$\mathcal{L}_{\text{rfn-bb}}$ определяется аналогичным образом.

\textbf{Потери циклической согласованности}

Важным свойством трекера должна быть циклическая согласованность, а именно: если $x^j = \Pi(x^i,j)$, то $x^i\approx\Pi(x^j,i)$. Функция потерь формулируется с учетом этого:
\begin{equation}
	\mathcal{L}_{\text{rfn-cc}} = \sum_{(x^i, x^j) \in \Omega_{\text{rfn-cc}}} \frac{1}{2} w_{\text{rfn-cc}}^{ij} \left( L_H(\Pi(x^i, j), x^j) + L_H(\Pi(x^j, i), x^i) \right),
\end{equation}
где $\{w_{\text{rfn-cc}}^{ij}\}$ --- веса, рассчитанные на основе ошибки циклической согласованности.

\textbf{Потери априорной информации}

Признаки полученные напрямую от DINOv2-ViT обладают высокой обобщающей способностью и содержат важную семантическую априорную информацию. Для ее сохранения вводится функция потерь, поощряющая сохранение нормы и ориентации уточненных признаков (для каждого кадра).
\begin{equation}
	\mathcal{L}_{\text{prior}} = \frac{1}{H' \cdot W'} \cdot \sum_p \left| 1 - \frac{\|\Phi(I)[p]\|_2}{\|\Phi_{\text{DINO}}(I)[p]\|_2}\right| + \left| 1 - \text{cos-sim}(\Phi(I)[p], \Phi_{\text{DINO}}(I)[p])\right|,
\end{equation}
где $H', W'$ --- размеры карты признаков.

\subsection{Обработка окклюзий}
Идея предсказания окклюзий на траектории $\mathcal{T}_q$ состоит в формировании набора опорных (anchor) кадров $\{I^{k_i}\}$ и сравнения признаков предсказанных на них точек с остальными признаками точек на траектории. Под опорными кадрами подразумеваются такие, где косинусное расстояние между признаками целевой точки и точек на них предсказанных выше определенного порога:
\begin{equation} \label{eq:anch}
	\text{cos-sim}(\varphi_q,\varphi_{k_i}) > \tau_{\text{anch}}
\end{equation}
Для каждого опорного кадра $k$ рассчитывается медианная невязка предсказания траектории (в сравнении с другими опорными кадрами):
\begin{equation}
	e_{k} = \text{med}_{k_i}(\|\Pi(\hat{x}^k,k_i) - \hat{x}^{k_i}\|)
\end{equation}
Точка $\hat{x}^t$ считается видимой если:
\begin{equation} \label{eq:occl}
	\begin{cases}
		\text{cos-sim}(\varphi_q, \varphi_t) \ge \tau_{\text{sim}}\\
		\text{med}(\|\Pi(x_q, k) - \Pi(\hat{x}_t, k)\|) < \text{max}_k(e_k)
	\end{cases},
\end{equation}
где $\tau_{\text{sim}}$ --- порог косинусного расстояния. 

Выбор такого алгоритма подкрепляется предположением согласования траекторий, а именно: предсказания на основе видимой точки как целевой будут достаточно близки к исходным (т.к. их признаки близки).

\subsection{Гиперпараметры}
В ходе выполнения данного тестового задания не проводилось исследование влияния гиперпараметров на качество обучения ввиду ограниченного времени и высоких вычислительных требований метода. Ниже приведены основные из них, рекомендуемые авторами с предположениями относительно интуиции их выбора.
\subsubsection{Параметры обучения}
В ходе обучения используется оптимизатор Adam как наиболее распространенный вариант. Благодаря адаптивному шагу градиентного спуска достигается более быстрая и стабильная сходимость.
Базовый шаг обучения выбран 0.01. Для части CNN-Refiner задано расписание уменьшения шага каждые 40 эпох: коэффициент затухания --- 0.999. Это позволяет избежать переобучения модели и добиться большей стабильности.

Весовые коэффициенты в формуле функции потерь \ref{eq:loss} эмпирически выбраны следующими: $\lambda_1=25\cdot 10^{-5}$, $\lambda_2=5\cdot 10^{-5}$, $\lambda_3=0.5$, $\lambda_4= 10^{-4}$.

Количество эпох выбирается в зависимости от длины видео. Для последовательностей около 100 кадров рекомендуется производить 10000 эпох, для более 250 кадров --- 20000.

Параметр температуры в уравнении \ref{eq:bb-loss} установлен $\tau=0.1$, что позволяет более явно выделить влияние пар точек с высокой корреляцией.

Функции потерь $\mathcal{L}_{\text{rfn-bb}}$ и $\mathcal{L}_{\text{rfn-cc}}$ применяются только после 5000 эпох, т.к. они рассчитаны на уже частично обученные работающие уточненные признаки.

\subsubsection{Параметры работы}
Радиус окрестности наиболее вероятной точки на карте распределения из формулы \ref{eq:prediction} выбран $R=35\text{px}$, что соответствует 5 токенам на карте признаков DINOv2 (с учетом шага токенизации 7).

Пороги используемые при выборе опорных кадров и предсказании окклюзий (\ref{eq:anch} и \ref{eq:occl}) установлены $\tau_{\text{anch}}=0.7$ и $\tau_{\text{sim}}=0.6$. Важно чтобы оба числа были достаточно велики (отражать сходство видимых точек с целевой), при этом $\tau_{\text{anch}} > \tau_{\text{sim}}$ для формирования набора опорных кадров как обладающих высшей уверенностью предсказания.

\newpage

\section{Запуск предобученной модели}
В данной секции представлены результаты использования модели DINO-Tracker на последовательностях из датасета 
Tapvid-Davis-480. Данные доступны по \href{https://www.dropbox.com/scl/fo/7s2rgsm92qbzzh2xnx51d/AIvXxRaJPL2RQm43Zi_taJU?e=1&preview=davis_480.zip&rlkey=6cs0bm2u0on1u7z0jyxlq8avq&st=7s75r77a&dl=0}{ссылке}, указанной в репозитории.
\subsection{Базовая визуализация}
В качестве примеров для демонстрации работоспособности базовой модели DINO-Tracker (предсказаний нейросетевой части, без предсказания окклюзий) были выбраны видео-последовательности с достаточно простым профилем движения, без явных окклюзий. На рисунках \ref{fig:davis-29}-\ref{fig:davis-21} изображены по 3 кадра (первый, центральный и последний) с демонстрацией промежуточных траекторий для целевых точек. Начальным кадром во всех случаях является первый.
\begin{figure}
    [H]
    \centering
    \includegraphics[width=\textwidth]{figs/davis-29.png}
    \caption{Траектории DINO-Tracker. Tapvid-Davis-480/29.}
    \label{fig:davis-29}
\end{figure}
\begin{figure}
    [H]
    \centering
    \includegraphics[width=\textwidth]{figs/davis-26.png}
    \caption{Траектории DINO-Tracker. Tapvid-Davis-480/26.}
    \label{fig:davis-26}
\end{figure}
\begin{figure}
    [H]
    \centering
    \includegraphics[width=\textwidth]{figs/davis-21.png}
    \caption{Траектории DINO-Tracker. Tapvid-Davis-480/21.}
    \label{fig:davis-21}
\end{figure}

Можем заметить, что полученные траектории имеют естественный вид. 
Базовый метод может быть успешно применен и к трекингу в более сложных окружениях 
(рисунок \ref{fig:davis-13}), однако важно чтобы целевая точка находилась в достаточно 
уникальной части изображения и не подвергалась окклюзиям. Например, на рисунке 
\ref{fig:davis-15} видно, что целевая точка сопоставляется неправильно с определенного 
момента времени (из-за появления схожего объекта и окклюзии первоначальной цели). 
Данные ограничения помогает во многом снять предсказание окклюзий, позволяющее определить валидность оценки.

\begin{figure}
    [H]
    \centering
    \includegraphics[width=\textwidth]{figs/davis-13.png}
    \caption{Траектории DINO-Tracker. Tapvid-Davis-480/13.}
    \label{fig:davis-13}
\end{figure}
\begin{figure}
    [H]
    \centering
    \includegraphics[width=\textwidth]{figs/davis-15.png}
    \caption{Траектории DINO-Tracker. Tapvid-Davis-480/15.}
    \label{fig:davis-15}
\end{figure}

Все эксперименты данной секции доступны в виде визуализаций на \href{https://drive.google.com/drive/folders/1lrNxilkdl0-vznN1TfMgSNOFz2cYQjS7?usp=drive_link}{диске} в двух вариантах --- видео с трекингом точек, соответсвующее рисункам (без проверки окклюзий) и видео трекингом множества сэмплированных точек (предложенные в датасете Tapvid-Davis-480 в качестве обучающих данных) с учетом окклюзий.

\subsection{Метрики качества}

Оценка качества трекинга производится на датасете Tapvid-Davis-480 согласно инструкции, указанной в репозитории (также есть возможность провести оценку на других предложенных наборах данных, однако ввиду длительности процесса был выбран один из них).

Для оценки используются метрики, предложенные в оригинальной статье <<TAP-Vid: A Benchmark for Tracking Any Point in a Video>>: 
\begin{enumerate}
    \item occlusion accuracy ($OA$) --- отношение количества правильно предсказанных окклюзий в  кадров к длине последовательности (стандартная accuracy классификации);
    \item position accuracy ($<\delta^x$) --- отношение количества правильно предсказанных положений видимых точек (без окклюзий) последовательности к количеству видимых точек, где правильными считаются предсказания, лежащие в заданной окрестности (в пикселях) действительных значений;
    \item jaccard --- объединенная метрика для оценки качества предсказаний окклюзий и положений, рассчитываемая как отношение количества правильно предсказанных положений видимых точек с соответствующим правильным предсказанием окклюзий последовательности к количеству видимых точек + количеству неправильно классифицированных невидимых точек или точек с неправильными предсказаниями положений, предсказанных видимыми.
\end{enumerate}
Важно отметить, что метрики $<\delta^x$ и jaccard рассчитываются для всех кадров (кроме начальных для соответствующих ключевых точек) с учетом приведения к размеру 256x256.
В качестве итоговых метрик выступают $OA$, average jaccard ($AJ$) и average position accuracy ($<\delta^x_{avg}$), где последние две рассчитываются как средние значения jaccard и $<\delta^x$ для окрестностей в 1, 2, 4, 8 и 16 пикселей.
\begin{table}[!ht]
    \centering
    \begin{tabular}{|l|l|l|l || l|l|l|l|}
    \hline
	\textbf{id} & \textbf{$OA$} & \textbf{$AJ$} & \textbf{$<\delta^x_{avg}$} & \textbf{id} & \textbf{$OA$} & \textbf{$AJ$} & \textbf{$<\delta^x_{avg}$} \\ \hline
        25 & 0.86407 & 0.52461 & 0.71564 & 23 & 0.88914 & 0.70477 & 0.8492 \\ \hline
        7 & 0.84293 & 0.62454 & 0.82839 & 14 & 0.95139 & 0.64647 & 0.75761 \\ \hline
        20 & 0.83599 & 0.5811 & 0.77156 & 13 & 0.89146 & 0.59985 & 0.72462 \\ \hline
        1 & 0.83536 & 0.55336 & 0.77867 & 29 & 0.96237 & 0.78638 & 0.87435 \\ \hline
        26 & 0.92519 & 0.72271 & 0.84825 & 17 & 0.89871 & 0.61162 & 0.75912 \\ \hline
        5 & 0.87887 & 0.60303 & 0.8446 & 4 & 0.87391 & 0.66864 & 0.88173 \\ \hline
        2 & 0.69653 & 0.37687 & 0.72344 & 11 & 0.79149 & 0.57035 & 0.7935 \\ \hline
        19 & 0.82501 & 0.47515 & 0.70126 & 16 & 1.0 & 0.94087 & 0.96645 \\ \hline
        6 & 0.85056 & 0.63005 & 0.80656 & 10 & 0.94926 & 0.76182 & 0.86853 \\ \hline
        22 & 0.79057 & 0.54181 & 0.76219 & 3 & 0.91635 & 0.75579 & 0.8585 \\ \hline
        8 & 0.88787 & 0.69386 & 0.84002 & 21 & 0.98371 & 0.84777 & 0.90917 \\ \hline
        28 & 0.93551 & 0.73576 & 0.84587 & 24 & 0.94805 & 0.8512 & 0.9379 \\ \hline
        0 & 0.99963 & 0.64083 & 0.72042 & 15 & 0.96577 & 0.80356 & 0.87399 \\ \hline
        9 & 0.69041 & 0.29614 & 0.5251 & 18 & 0.81178 & 0.52368 & 0.71774 \\ \hline
        27 & 0.87957 & 0.62347 & 0.7801 & 12 & 0.99365 & 0.88775 & 0.93579  \\ \hline
        \hline
        \textit{\textbf{avg}} & \textit{\textbf{0.8855} }& \textit{\textbf{0.65279}} & \textit{\textbf{0.80668}} & --- & --- & --- & --- \\ \hline
    \end{tabular}
	\caption{Метрики качества. Датасет Tapvid-Davis-480.}
\end{table}

В статье заявлены следующие данные для рассматриваемого датасета:
$OA=0.881, AJ=0.646, <\delta^x_{avg}=0.804$. Эксперимент подтверждает достижение таких значений.

Расширенный файл, содержащий метрики, доступен на \href{https://drive.google.com/file/d/1NcQksZNBh9HBexJbsNAwEITHeBhoiuUi/view?usp=drive_link}{диске}.
\subsection{Производительность}
Эксперименты производятся на устройстве Lenovo Legion 7 (AMD Ryzen 9 5900HX, NVIDIA GeForce RTX 3080 120W 16Gb, 32 Gb RAM).

Для получения данных о производительности в инференсе метод был применен ко всем последовательностям из датасета. Эксперимент проводился только для нейросетевой части DINO-Tracker. Дальнейшее предсказание окклюзий сильно зависит от контекста изображения, а точнее --- от количества выбранных опорных кадров для обработки.
На вход модели подавалась одна ключевая точка, соответсвующая центру первого кадра. Принятый размер батча: $1$.
Ниже приведен график, иллюстрирующий зависимость времени обработки видео от количества кадров в нем. 
\begin{figure}
    [H]
    \centering
    \includegraphics[width=\textwidth]{figs/performance.png}
    \caption{Зависимость времени инференса нейросетевой части DINO-Tracker от количества кадров.}
    \label{fig:performance}
\end{figure}

Алгоритм обработки видео последовательно предсказывает положение целевой точки на кадрах. Данные подтверждают, что зависимость является линейной. Аппроксимировав ее моделью линейной регрессии без смещения получим, что на предсказание позиции целевой точки в одном кадре тратится в среднем $0.0041$ [с]. В процессе инференса в среднем затрачивалось 14.5 Гб видеопамяти.

Стоит уточнить, что процесс инференса производится с учетом заранее рассчитанных карт признаков DINOv2-ViT и по сути представляет собой работу DELTA-DINO и CNN-Refiner. Подробнее техническое описание представлено в секции <<Техническая информация>>.

\subsection{Мульти-трекинг}
Задача множественного трекинга объектов подразумевает наличие механизма сопоставление объектов с траекториями движения (ассоциация данных). Базовый метод DINO-Tracker не использует данную процедуру. Как видно на примерах, представленных выше (рисунки \ref{fig:davis-13}, \ref{fig:davis-15}) в такой конфигурации он может быть применен при отсутствии явных окклюзий и достаточном количестве семантически уникальных точек на объектах.

При использовании предсказания окклюзий область применения метода для задач множественного трекинга можно существенно расширить. В алгоритме обработки окклюзий частично применяется подход ассоциации --- проверяется схожесть траекторий на разных участках видео согласно установленному критерию. На рисунке \ref{fig:davis-8} показаны положения целевых точек (1 и 30 кадр), изначально расположенных на объектах.
\begin{figure}
    [H]
    \centering
    \includegraphics[width=\textwidth]{figs/davis-8.png}
    \caption{Трекинг точек на нескольких объектах. Tapvid-Davis-480/8.}
    \label{fig:davis-8}
\end{figure}

Можно предположить, что произведя изначальную детекцию объектов и сформировав наборы целевых точек, соответствующих им, производить трекинг объектов путем расчета среднего положения всех их видимых точек.
Однако такой подход требует усовершенствования для обработки новых объектов появляющихся на видео (что в итоге возвращает к задаче верхнеуровневой ассоциации данных). Кроме того, даже с учетом обработки окклюзий семантически близкие точки могут неверно сопоставляться, ухудшая качество оценки положения.
\newpage

\section{Запуск на собственных данных}
В данной секции приведены результаты экспериментов на данных, снятых на телефон. Видео были приведены к формату, используемом в датасете Tapvid-Davis-480 (изображения 480x854, 10fps, длина до 200 кадров) и разбиты на кадры (архивы могут быть найдены на \href{https://drive.google.com/drive/folders/1kL4srq3aIuJvA-0jlK886FdR1ZIgu8Ui?usp=drive_link}{диске}). 

\subsection{Описание данных}
Всего записано 4 видео, демонстрирующих различные ситуации, в которых может быть применим трекинг:
\begin{enumerate}
	\item взаимодействие объектов с простым профилем движения;
	\item взаимодействие объектов со сложным профилем движения;
	\item движение объекта с изменением плана;
	\item движение объекта с сохранением плана.
\end{enumerate}

На каждом видео из собранных присутствуют незначительные окклюзии. На видео 2 и 4 присутствуют семантических схожие объекты. 
\begin{figure}
    [H]
    \centering
    \includegraphics[width=\textwidth]{figs/custom_expl.png}
    \caption{Примеры кадров из собранных видео.}
    \label{fig:custom-expl}
\end{figure}

\subsection{Обучение}

Первым этапом является предобработка изображений --- вычисление карт признаков DINOv2-ViT, расчет оптического потока и нахождение семантически схожих точек. Данный процесс занимает в среднем 30-40 минут. Сам процесс обучения длится около полутора часов (10000 эпох).
Затрачиваемое количество видеопамяти достигало 21 Гб. В связи с этим оно проводилось на отличном от выше указанного оборудовании: Intel 11th Gen Core i7-11700, NVIDIA GeForce RTX 3090 450W 24Gb, 32Gb RAM.

\subsection{Результаты экспериментов}
Все эксперименты проводились путем сэмплирования 100 точек в зоне интереса и предсказания траекторий для них, а также предсказанием окклюзий (на изображениях показаны 3 случайных точки объекта, в видео-материалах отображены все). Инференс производился на том же оборудовании, что и обучение. Размер батча был выбран 50 как оптимальный по времени работы и удовлетворяющий требованиям памяти в большинстве случаев для видео из датасета Tapvid-Davis-480. Видео-визуализации с результатами испытаний доступны на \href{https://drive.google.com/drive/folders/1jyuXTmpgYpkRt16hLX30Lu-oDO__paxN?usp=drive_link}{диске}.

\subsubsection{Видео 1}
\begin{itemize}
	\item количество кадров: 119;
	\item время обработки: 2 мин 20 с.
\end{itemize}

На рисунке \ref{fig:custom-1} продемонстрированы траектории на части видео (для удобства визуализации). Сэмплинг целевых точек происходил в зоне взаимодействия руки и мяча. Однако в итоге видимыми (без окклюзий) были классифицированы только целевые точки, находящиеся на руке. Их трекинг оказался стабильным и точным. Среди возможных причин неудачи трекинга мяча стоит выделить малый размер объекта и высокую скорость движения --- из-за этого изображение теряет исходный вид и семантическую информацию. 
\begin{figure}
    [H]
    \centering
    \includegraphics[width=\textwidth]{figs/custom-1.png}
    \caption{Траектории DINO-Tracker. Custom/1.}
    \label{fig:custom-1}
\end{figure}

\subsubsection{Видео 2}
\begin{itemize}
	\item количество кадров: 157;
	\item время обработки: ---.
\end{itemize}
Обучение для видео 2 не удалось запустить (требовалось более 24 Гб видеопамяти).

\subsubsection{Видео 3}
\begin{itemize}
	\item количество кадров: 69;
	\item время обработки: 22 с.
\end{itemize}

На рисунке \ref{fig:custom-3} изображены предсказанные положения мяча. Как и в видео 1 трекинг мяча становится несостоятельным как только он начинает быстрое движение или изменение размера (из-за отдаления) и теряет четкость. В \href{https://drive.google.com/file/d/1u9dOc59ZkDruSFHMgPoj0jT528nW_ne4/view?usp=drive_link}{видео-визуализации} трекинга можно заметить, что предсказания остаются стабильными первые несколько кадров до момента броска.
\begin{figure}
    [H]
    \centering
    \includegraphics[width=\textwidth]{figs/custom-3.png}
    \caption{Траектории DINO-Tracker. Custom/3.}
    \label{fig:custom-3}
\end{figure}

На основе данных экспериментов 1 и 3 можно выдвинуть предположение, о чувствительности метода к искажениям изображения при быстром движении объекта малых размеров. Также нежелательно наличие значимых окклюзий в данном случае. Пример стабильного и точного трекинга руки (также являющейся небольшим объектом) в эксперименте 1 демонстрирует возможность работы метода в отсутствии указанных выше эффектов.

\subsubsection{Видео 4}
\begin{itemize}
	\item количество кадров: 50;
	\item время обработки: 57 с.
\end{itemize}

На рисунке \ref{fig:custom-4} представлен трекинг движущегося автомобиля. Это пример простого профиля движения с окклюзиями. Можем наблюдать стабильный и качественный трекинг объекта. На \href{https://drive.google.com/file/d/1c1rivtgAYqveos9xyPtBjhV8Nz-x64h2/view?usp=drive_link}{видео-визуализации} заметно, что траектории нескольких точек определяются некорректно после контакта объекта с семантически близким ему (другим автомобилем). 
\begin{figure}
    [H]
    \centering
    \includegraphics[width=\textwidth]{figs/custom-4.png}
    \caption{Траектории DINO-Tracker. Custom/4.}
    \label{fig:custom-4}
\end{figure}

\subsubsection{Проверка обобщаемости}
В статье авторы не приводят данных об обобщающей способности обученной модели (качество работы для семантически схожих окружений и объектов). В этом эксперименте предлагается проверить работоспособность моделей, обученных на видео из датасета Tapvid-Davis-480 при обработке представленного выше видео 4.

Видео Tapvid-Davis-480/1 обладает схожими чертами с видео 4 (также демонстрирует движение автомобиля --- рисунок \ref{fig:davis-1-expl}). В предположении об инвариантности DINOv2 признаков к размеру была выдвинута гипотеза о применимости модели к видео 4.
\begin{figure}
    [H]
    \centering
    \includegraphics[width=\textwidth]{figs/davis-1_expl.png}
    \caption{Пример кадра. Tapvid-Davis-480/1.}
    \label{fig:davis-1-expl}
\end{figure}

Обработка видео заняла 10 с. Результат трекинга изображен на рисунке \ref{fig:custom-4-sem}. Качество трекинга заметно ухудшилось.
\begin{figure}
    [H]
    \centering
    \includegraphics[width=\textwidth]{figs/custom-4-sem.png}
    \caption{Траектории DINO-Tracker (модель обученная на семантически схожем видео). Custom/4.}
    \label{fig:custom-4-sem}
\end{figure}

Для сравнения эксперимент был также проведен на видео Tapvid-Davis-480/15, обладающим совершенно отличным контекстом. Время обработки составило 11 с. Результат представлен на рисунке \ref{fig:custom-4-bad-sem}. Качество детекции сопоставимо с предыдущим результатом --- предположительно априорные признаки DINOv2 довольно хорошо сохраняют свою структуру после уточнения моделью DELTA-DINO, привносящей в основном информацию о временных связях в конкретном видео для которого было проведено обучение.
\begin{figure}
    [H]
    \centering
    \includegraphics[width=\textwidth]{figs/custom-4-bad-sem.png}
    \caption{Траектории DINO-Tracker (модель обученная на семантически отличном видео). Custom/4.}
    \label{fig:custom-4-bad-sem}
\end{figure}

Заметим, что время обработки заметно снижено по сравнению с использованием тренированной на видео 4 модели. Это связано с уменьшенным количеством опорных кадров при обработке окклюзий (из-за сниженной корреляции между признаками разных кадров их отбирается меньше).

На основе данных экспериментов можно предположить, что для качественного обобщения требуется более близкая семантика изображений или обученная DELTA-DINO в целом обладает плохой обобщающей способностью.

\newpage


\section{Техническая информация} 
В данной секции рассматривается процесс установки необходимого ПО и его использования для проведения экспериментов, описанных в предыдущих секциях. В ходе работы над тестовым заданием был создан \href{https://github.com/diuzhevVlad/dino-tracker-assignment.git}{fork} оригинального репозитория, содержащий некоторые утилитарные скрипты и интерактивные блокноты. 

Для начала работы с репозиторием:
\lstset{style=mystyle}
\begin{lstlisting}[language=bash]
git clone https://github.com/diuzhevVlad/dino-tracker-assignment.git
\end{lstlisting}

\subsection{Настройка окружения}
В оригинальном репозитории авторы предлагают использовать окружение conda на основе python3.9. При использовании официальной инструкции возникают проблемы совместимости версий библиотек. Необходимо указать версию \textit{numpy 1.26.0} в файле \textit{requirements.txt}. Данное исправление сделано в указаном выше репозитории.

Для создания окружения:
\lstset{style=mystyle}
\begin{lstlisting}[language=bash]
conda create -n dino-tracker python=3.9 
conda activate dino-tracker 
pip install -r requirements.txt
\end{lstlisting}

Для удобного добавления репозитория в \textit{PYTHONPATH}:
\begin{lstlisting}[language=bash]
conda install conda-build
conda develop .
\end{lstlisting}

\subsection{Загрузка датасетов}
Для использования датасетов их файлы архивов достаточно распаковать в директорию \textit{dataset}. В ходе выполнения задания использовались \href{https://drive.google.com/file/d/15iur2U_639eWnykylz69-RPGT6p3Ip8u/view?usp=drive_link}{custom} и \href{https://www.dropbox.com/scl/fo/7s2rgsm92qbzzh2xnx51d/AIvXxRaJPL2RQm43Zi_taJU?e=1&preview=davis_480.zip&rlkey=6cs0bm2u0on1u7z0jyxlq8avq&st=7s75r77a&dl=0}{Tapvid-Davis-480}. Первый содержит только сырые кадры 4 четырех снятых видео. Второй включает в себя помимо этого сегментационные маски для построения репрезентативных визуализаций, а также предобученные модели DELTA-DINO и CNN-Refiner (tracker head).

\subsection{Получение метрик для Tapvid-Davis-480}
Для упрощения процедуры оценки качества на рекомендуемом авторами датасете были написаны два скрипта-оркестратора, оперирующие другими предоставляемыми авторами скриптами.

Запустить расчет DINOv2 признаков для всех видео датасета:
\begin{lstlisting}[language=bash]
python3 benchmarking/preprocess_benchmark.py
\end{lstlisting}
В ходе работы будет выполнен скрипт \textit{preprocessing/save\_dino\_embed\_video.py} для всех видео датасета. В результате во всех директориях \textit{dataset/tapvid-davis/\{i\}} должна появиться папка \textit{dino\_embeddings}, содержащая файлы признаков.

Запустить расчет траекторий ключевых точек, для которых предусмотрены ground-truth данные:
\begin{lstlisting}[language=bash]
python3 benchmarking/inf_benchmark.py
\end{lstlisting}
В ходе работы будет выполнен скрипт \textit{inference\_benchmark.py} для всех видео датасета. В результате во всех директориях \textit{dataset/tapvid-davis/\{i\}} должны появиться папки \textit{occlusions} и \textit{trajectories}, содержащие файлы предсказаний траекторий и окклюзий для целевых точек.

Для расчета метрик и сохранения в файл:
\begin{lstlisting}[language=bash]
python3 ./eval/eval_benchmark.py \
    --dataset-root-dir ./dataset/tapvid-davis \
    --benchmark-pickle-path ./tapvid/tapvid_davis_data_strided.pkl \
    --out-file ./tapvid/comp_metrics_davis.csv \
    --dataset-type tapvid 
\end{lstlisting}

В зависимости от мощности используемого оборудования весь процесс может занять до 4 часов.

\subsection{Обучение}
Процесс обучения подробно описан в оригинальной инструкции и состоит из запуска скриптов предобработки (\textit{preprocessing/main\_preprocessing.py}) для расчета DINOv2 признаков, а также оптического потока и нахождения семантически схожих точек (best-buddies), и непостредственно скрипта обучения \textit{train.py} с соответсвующими параметрами.

Оригинальные скрипты не предполагают процесса логирования (в том числе в wandb). Единственным индикатором выполнения является progressbar с текущим статусом.

\subsection{Инференс}
Все эксперименты, связанные с инференсом моделей, а также утилитарные функции, упрощающие взаимодействие с базовыми классами, представлеными в репозитории, произведены в интерактивном блокноте \\ \textit{visualization/playground.ipynb}. Использование данного файла предполагает проведение этапа инференса бенчмарка Tapvid-Davis и обучение моделей на датасете Custom (суммарно файлы весов и предсказанных траекторий/окклюзий для всех видео занимают слишком большое количество памяти для загрузки на диск, однако могут быть предоставлены по просьбе).

Алгоритм проведения визуализации множества точек в виде сетки подробно описан в официальной инструкции, однако стоит отметить, что такой вид визуализации подходит при наличии ground-truth сегментационных масок (иначе данные плохо интерпретируемы).

Пример визуализации нейросетевой модели посредством библиотеки \textit{torchview} расположен в файле \textit{visualization/model\_visualization.ipynb}. Из-за сложной структуры исходных классов моделей их не удалось конвертировать в формат onnx для более качественной визуализации.

\newpage


\section{Выводы}

В рамках данного отчета была изучена статья \textit{"DINO-Tracker: Taming DINO for Self-Supervised Point Tracking in a Single Video"}, проведен анализ архитектуры модели и дополнительных алгоритмов. Кроме того, проведено техническое описание предоставленного авторами репозитория. Основные выводы представлены ниже:

\begin{enumerate}
    \item \textbf{Эффективность модели DINO-Tracker}:
    \begin{itemize}
        \item Модель показывает высокую точность трекинга точек, даже при сложных условиях, таких как длительные окклюзии и изменяющийся фон, что демонстрируется на данных бенчмарка Tapvid-Davis. Стоит отметить, что в ходе испытаний с видео, снятыми в повседневной среде на телефон, возникает существенное падение точности. В частности, трекинг нестабилен для малых объектов и объектов движущихся с большой скоростью. Данный эффект может быть связан с уступающим качеством камеры, используемой для съемки. 
        \item Согласно данным статьи, метод превосходит большинство известных подходов трекинга на основе нейросетевых моделей (в том числе на основе обучения с учителем). В ходе выполнения задания не проводилось их сравнение, однако полученные метрики для данной модели совпадают с заявленными.
    \end{itemize}

    \item \textbf{Сильные стороны подхода}:
    \begin{itemize}
        \item Модель не требует размеченных данных благодаря использованию методов self-supervised learning, что делает её потенциально полезной для работы с большими видеодатасетами, не обладающими разметкой данных (в задаче трекинга это особенно трудоемкий процесс).
        \item Интеграция требований семантического соответствия (best-buddies) и циклической согласованности позволяет повысить стабильность.
        \item Эксперименты указывают на сохранение большей части априорной информации от DINOv2 признаков (что ставилось авторами как одна из целей), при этом добавление к ним контекстной и временной информации. Это может позволить использовать модель DELTA-DINO не только для задачи трекинга, но также для формирования более качественных признаков изображений используемых в конкретном видео.
    \end{itemize}

    \item \textbf{Ограничения}:
    \begin{itemize}
        \item Рассматриваемый метод обладает значительными требованиями к оборудованию, на котором производится обучение и инференс. В частности, необходимо минимум 16 Гб видеопамяти только для использования метода на небольших последовательностях кадров. Это значительно ограничивает его применение на портативных устройствах.
        \item Скорость обработки видео может быть приближена к реальному времени при наличии достаточно мощных вычислительных устройств. В ходе экспериментов было показано, что само предсказание траекторий выполняется достаточно быстро (0.004 [с] для размера батча 1). Большую часть времени занимает предсказание окклюзий. Оценить длительность этого процесса сложно т.к. он зависит от контекста видео и качества признаков DINOv2, что влияет на количество опорных кадров (причем на видео без значительных окклюзий и искажений их будет найдено больше, что повысит время обработки). Кроме того все эксперименты проводились с использованием заранее рассчитаных DINOv2 признаков (так подразумевает архитектура предоставленного ПО) и в реальных приложениях необходимо учитывать время, затрачиваемое на их экстракцию.
        \item Как было показано, алгоритм может не обладать значительной обобщающей способностью --- качество трекинга сильно снижается при использовании модели обученной на отличном от инференса видео. Эффект наблюдался даже при семантическом и контекстуальном сходстве последовательностей. Однако для подтверждения необходимо проведение большего количества экспериментов. Теоретически это может быть обусловленно <<выучиванием>> моделью уникальной контектсной информации, что позволяет улучшить качество признаков для трекинга, но ухудшает обобщающую способность.
        \item Можно выделить также неспособность предсказывать валидное положение окклюдированных точек.
    \end{itemize}

    \item \textbf{Качество ПО}
    \begin{itemize}
        \item Предоставленный авторами репозиторий позволяет проверить основные результаты, представленные в статье. Разработанные авторами скрипты предоставляют удобный, но ограниченный функционал для верхнеуровневого обучения, использования и оценки качества метода.
        \item Для использования ПО в целях выполнения реальной задачи или постановки собственных экспериментов необходимы существенные модификации. Текущая структура ПО носит скорее демонстрационный характер.
        \item На данный момент не предусмотрены механизмы логирования данных в процессе обучения. Также текущая структура не допускает прямую конвертацию в универсальный формат onnx.
    \end{itemize}

    \item \textbf{Идеи по улучшению}:
    \begin{itemize}
        \item Для ускорения работы метода необходимо оптимизировать алгоритм экстракции признаков и обработку окклюзий (как было показано --- наиболее длительные процессы). Модель DINOv2-ViT является уже хорошо оптимизированной и из возможных вариантов ускорения доступны смена модели экстракции или использование признаков с более низких слоев (необходимо провести исследование качества). 
        \item В качестве меры ускорения обработки опорных кадров можно принять ограничение максимального их количества в зависимости от длины видео. В данной реализации количество опорных кадров не ограничено и в некоторых случаях может приводить к избыточным затратам ресурсов и времени.
        \item Для повышения качества работы метода возможным нововведением является добавление аугментированных данных в процессе обучения. Например, после расчета оптического потока и семантически схожих точек добавлять точечные размытия на изображения, рассчитывать для них DINOv2 признаки и использовать в обучающей выборке вместе с оригинальным кадром. Такой подход возможно уменьшил бы чувствительность метода к искажениям (действительно размытые части изображения обрабатывались бы точнее за счет наличия в обучающей выборке ground-truth данных для аугментированных частей).
    \end{itemize}

    \item \textbf{Перспективы применения}:
    \begin{itemize}
        \item Модель может быть использована для задач оффлайн обработки видео, анализа показаний камер наблюдения в различных приложениях, требующих высокой точности трекинга.
        \item На данный момент применение метода в реальном времени затруднено высокими вычислительными требованиями и необходимостью обучения на конкретном видео перед использованием. 
        \item DINO-Tracker является перспективным инструментом и бэйзлайном для проведения будущих исследований методов компьютерного зрения для задач трекинга, а также в целом подходов self-supervised learning.
    \end{itemize}
\end{enumerate}

\newpage


\end{document}
\input{metrics_table}

